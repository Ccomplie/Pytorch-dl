{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import time\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms,utils\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "# 预先定义图像归一化方式，归一化后取值在[-1.0，1.0]\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5],std=[0.5])])\n",
    "\n",
    "#加载数据\n",
    "train_dataset = datasets.FashionMNIST(root='./data', \n",
    "                                            train=True, \n",
    "                                            transform=transform, \n",
    "                                            download=True)  #是否从网络下载\n",
    "test_dataset = datasets.FashionMNIST(root='./data', \n",
    "                                            train=False, \n",
    "                                            transform=transform, \n",
    "                                            download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#批量数128，随机乱序\n",
    "batch_size = 128\n",
    "shuffle = True\n",
    "#采用小批量方式加载数据\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True, # 装载过程中随机乱序\n",
    "                                            num_workers=1) \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=False,\n",
    "                                            num_workers=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型网络结构超参数，输入28*28， 隐藏层256，输出层10\n",
    "num_inputs = 28*28\n",
    "num_hidens = 256\n",
    "num_outputs = 10\n",
    "\n",
    "\n",
    "#交叉熵损失函数，包含softmax\n",
    "loss = nn.CrossEntropyLoss()\n",
    "#使用Sequential类定义模型结构\n",
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(num_inputs, num_hidens),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(num_hidens, num_outputs)\n",
    ")\n",
    "\n",
    "for param in net.parameters():\n",
    "    nn.init.normal_(param, mean=0, std=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_acc(data_iter, net):\n",
    "    acc_count, n = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_iter:\n",
    "            x = x \n",
    "            y = y \n",
    "            y_hat = net(x)\n",
    "            acc_count += acc(y_hat, y)\n",
    "            n += y.size(0)\n",
    "    return acc_count/n \n",
    "\n",
    "def acc(y_hat, y):\n",
    "    _, pre_labels = torch.max(y_hat, dim=1) # 将每个预测结果中最大输出的索引作为分类标签，pre_labels为小批量中每个样本预测结果的向量\n",
    "    acc_count = (pre_labels == y).sum().item()\n",
    "    return acc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_acc(data_iter, net):\n",
    "    acc_count, n = 0, 0\n",
    "    for x, y in data_iter:\n",
    "        y_hat = net(x)\n",
    "        acc_count += acc(y_hat, y)\n",
    "        n += y.size(0)\n",
    "    return acc_count/n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 617.7785, train_acc: 0.5747, test_acc: 0.7218\n",
      "epoch: 2, loss: 328.9127, train_acc: 0.7485, test_acc: 0.7610\n",
      "epoch: 3, loss: 280.2154, train_acc: 0.7828, test_acc: 0.7860\n",
      "epoch: 4, loss: 254.2215, train_acc: 0.8071, test_acc: 0.8030\n",
      "epoch: 5, loss: 237.9509, train_acc: 0.8207, test_acc: 0.8136\n",
      "epoch: 6, loss: 226.7706, train_acc: 0.8294, test_acc: 0.8177\n",
      "epoch: 7, loss: 218.7779, train_acc: 0.8361, test_acc: 0.8233\n",
      "epoch: 8, loss: 212.7117, train_acc: 0.8401, test_acc: 0.8285\n",
      "epoch: 9, loss: 207.3938, train_acc: 0.8440, test_acc: 0.8293\n",
      "epoch: 10, loss: 203.1178, train_acc: 0.8481, test_acc: 0.8342\n"
     ]
    }
   ],
   "source": [
    "#定义学习率\n",
    "lr = 0.05\n",
    "epoch = 10\n",
    "opt = optim.SGD(net.parameters(), lr)\n",
    "\n",
    "def train(net, train_iter, test_iter, num_epoch, opt, loss):\n",
    "    train_acc_list, test_acc_list, train_loss_list, test_loss_list = [], [], [], []\n",
    "    for epoch in range(num_epoch):\n",
    "        train_acc_sum, train_loss_sum, n, =0, 0, 0\n",
    "        for x, y in train_iter:\n",
    "            opt.zero_grad()\n",
    "            y_hat = net(x)\n",
    "            l = loss(y_hat, y).sum()\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "            train_loss_sum += l.item()\n",
    "            train_acc_sum += acc(y_hat, y)\n",
    "            n += y.size(0)\n",
    "        test_acc = evaluate_acc(test_iter, net)\n",
    "        train_acc = train_acc_sum/n\n",
    "        print(f\"epoch: {epoch+1}, loss: {train_loss_sum:.4f}, train_acc: {train_acc:.4f}, test_acc: {test_acc:.4f}\")   \n",
    "    return \n",
    "train(net, train_loader, test_loader, epoch, opt, loss)         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
